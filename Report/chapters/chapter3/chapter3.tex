\chapter{Problem Pre-processing}
\section{The problem}
The goal of the semester project is to unravel the emotion pattern underlying the sequences of songs in a playlist using automatic approaches of Emotion Detection on the lyrics.\par
The problem can be divided into two main parts:
\begin{enumerate}
\item Classify emotions for each song based on the lyrics
\item Analyze emotion patterns in the playlists
\end{enumerate}

\section{Related work}
Emotion detection domain has already attracted many researchers from computer science, psychology, cognitive science and so on. \par
Before building our own emotion detection system we start analyzing some already existent classifier. \par
\paragraph{IBM Watson Natural Language Understanding}\cite{ibm_watson}
Watson is a question answering computer system capable of answering questions posed in natural language, developed by IBM.\par
Natural Language Understanding is a collection of APIs that allows to:
\begin{itemize}
\item Recognize the overall sentiment, in a scale from negative to positive [-1, 1];
\item Detect the emotion percentage between: joy, anger, disgust, sadness, fear;
\item Determine keywords ranked by relevance;
\item Extract entities: people, companies, organizations, cities and other information;
\item Classify content into hierarchical categories;
\item Identify general concepts that may not be directly referenced in the text; 
\end{itemize}
Results obtained analyzing Oasis - Wonderwall are illustrated in Fig.


\paragraph{IBM Watson Tone Analyzer}\cite{ibm_watson_tone}
It uses linguistic analysis to detect joy, fear, sadness, anger, analytical, confident, and tentative tones found in text. It allows to select different sources: tweets, online reviews, email messages, or other text. It uses both:
\begin{itemize}
\item the document level: to get a sense of the overall tone;
\item the sentence level: to identify specific areas where tones are the strongest.
\end{itemize}

\paragraph{QEmotion}\cite{qemotion}
Qemotion detects the main emotion of the speech and define the corresponding emotion in terms of temperature. 
\begin{itemize}
\item From $31^{\circ}$ to $40^{\circ}$ $\to$ Happiness
\item From $21^{\circ}$ to $30^{\circ}$ $\to$ Surprise
\item From $11^{\circ}$ to $20^{\circ}$ $\to $ Calm
\item From $6^{\circ}$ to $10^{\circ}$ $\to $ Fear
\item From $-5^{\circ}$ to $5^{\circ}$ $\to $ Sadness
\item From $-14^{\circ}$ to $-6^{\circ}$ $\to $ Anger
\item From $-20^{\circ}$ to $-15^{\circ}$ $\to $ Disgust
\end{itemize}


\section{NLP libraries}
In order to select the best Natural Language Processing library for our purpose we also analyzed pros and cons of the main Natural Language Processing libraries, i.e. NLTK, TextBlob, Standord's CoreNLP and SpaCy. 

\paragraph{NLTK: Natural Language Toolkit}
It is recommended only as an education and research tool. \\
Pros:
\begin{itemize}
\item its modularized structure makes it excellent for learning and exploring NLP concepts; 
\item over 50 corpora and lexicons, 9 stemmers, and a dozens of algorithms to choose from (this can also be considered as a con).
\end{itemize}
Cons: 
\begin{itemize}
\item Heavy library with a steep learning curve;
\item Slow and not production-ready. 
\end{itemize}

\paragraph{TextBlob}
Built on top on NLTK.\\
Pros: 
\begin{itemize}
\item More intuitive; 
\item Gentle learning curve. 
\end{itemize} 

\paragraph{Stanford's CoreNLP}
Java library with Python wrappers. \\
Pros:
\begin{itemize}
\item fast;
\item support for several major languages. 
\end{itemize}

\paragraph{SpaCy}
It is a new NLP library designed to be fast, streamlined and production-ready.\\
Pros:
\begin{itemize}
\item minimal number of options;
\item its philosophy is to only present the best algorithm for each purpose. 
\end{itemize}
Cons:
\begin{itemize}
\item it is new, so its support community is not as large as other libraries, but it is growing very fast.
\end{itemize}





\section{Word embedding techniques}
Word embeddings are a set of feature learning techniques mapping words or phrases from the vocabulary to vectors or real numbers. \par
These techniques map sparse word vectors into continuous space based on the surrounding context. For example if \textit{``salt''} and \textit{``seasoning''} appear within the same context, the model will indicate that \textit{``salt''} is conceptually closer to \textit{``seasoning''}, than another word, say \textit{``chair''}.\par
There are two main embedding libraries: Word2vec and FastText. While Word2vec treats each word in corpus like an atomic entity generating a vector for each word, FastText treats each word as composed of character ngrams, so the vector for a word is made of the sum of this character n grams. \par
For example,  the word vector \textit{``apple''} is a sum of the vectors of the n-grams ``ap'', ``app'', ``appl'', ``apple'', ``ppl', ``pple'', ``ple'', ``le'' assuming 3 and 6 as minimum and maximum ngrams size.\\
The difference between Word2vec and FastText manifests as follows:
\begin{enumerate}
\item \textit{Rare words}: even if words are rare, their character n-grams are still shared with other words - hence the embeddings with FastText can still be good;
\item \textit{Out of vocabulary words}: FastText can construct the vector for a word from its character n-grams even if word does not appear in training corpus;
\item \textit{Hyperparameters choice}: FastText requires to  choose the minimum and maximum n-grams sizes, and this directly impacts the computation time and the memory requirements. 
\end{enumerate}




\section{Public datasets}
A big challenge in emotion detection is the lack of a labelled emotion database to enable active innovation. Currently, few publicly accessible databases are available.\\\textit{MoodyLyrics}\cite{moodylyrics} contains around 2500 songs manually annotated through Amazon Mechanical Turk with 4 different emotion, i.e., happy, sad, angry and relaxed.\\
\textit{EmoInt}\cite{emoint} contains manually annotated tweets classified according to the intensities of anger, fear, joy and sadness. \textit{EmoBank}\cite{emobank} instead contains 10.000 sentences, each of which has been annotated according to both the emotion expressed by the writer and the emotion perceived by the reader. 




\section{Feature Engineering}
Once we were able to collect data to be used as golden standard for our classification process, we focused our attention on feature engineering. Specifically we tried to extract stylometric, structural, orientation and vocabulary based features\cite{features}. Apart from this we also generated a word embedding vector of the words contained in each song's lyric by using SpaCy's\cite{spacy} pre-trained language model based on word2vec\cite{word2vec}.

Here is a comprehensive list of the features we extracted from our dataset, followed by a brief description:

\begin{description}
\item \textbf{Title\_vector}: word embedding vector of the song's title
\item \textbf{Lyric\_vector}: word embedding vector of the lyric content
\item \textbf{\%Rhymes}: defined as the percentage of the number of rhymes over the number of total lines. A rhyme is defined as a rhyme between two following lines
\item \textbf{Line\_count}: number of lines in the lyric
\item \textbf{Word\_count}: number of words in the lyric
\item \textbf{\%Past\_tense\_verbs}: defined as the the percentage of the number of past tense verbs over the total number of verbs
\item \textbf{\%Present\_tense\_verbs}: defined as the the percentage of the number of present tense verbs over the total number of verbs
\item \textbf{\%Future\_tense\_verbs}: defined as the the percentage of the number of future tense verbs over the total number of verbs, where future is just will + base form
\item \textbf{\%ADJ}: percentage of adjectives over the total number of words
\item \textbf{\%ADP}: percentage of adpositions (e.g. in, to, during) over the total number of words
\item \textbf{\%ADV}: percentage of adverbs (e.g. very, tomorrow, down, where, there) over the total number of words
\item \textbf{\%AUX}: percentage of auxiliaries (e.g. is, has (done), will (do), should (do)) over the total number of words
\item \textbf{\%INTJ}: percentage of interjections (e.g. psst, ouch, bravo, hello) over the total number of words
\item \textbf{\%NOUN}: percentage of nouns over the total number of words
\item \textbf{\%NUM}: percentage of numerals over the total number of words
\item \textbf{\%PRON}: percentage of pronouns (e.g. I, you, he, she, myself, themselves, somebody,...) over the total number of words
\item \textbf{\%PROPN}: percentage of proper nouns (e.g. Mary, John) over the total number of words
\item \textbf{\%PUNCT}: percentage of puntuctuation (e.g. ., (, ), ?) over the total number of words
\item \textbf{\%VERB}: percentage of verbs over the total number of words
\item \textbf{Selfish\_degree}: percentage of 'I' pronouns over the total number of pronouns
\item \textbf{\%Echoism}: percentage of echoism over the total number of words, where an echoism is either a sequence of two subsequent repeated words or the repetition of a vowel in a word
\item \textbf{\%Duplicate\_Lines}: number of lines duplicated across the lyric text
\item \textbf{isTitleInLyric}: boolean, true if the title string is also a substring of the lyric
\item \textbf{Sentiment}: sentiment between -1 and 1
\item \textbf{Subjectivity\_degree}: degree of subjectivity of the text
\end{description}

Since the word embedding vectors we generated had length 300, at the end we were able to obtain 623 distinct numerical features for each of the songs in our dataset.

\subsection{Feature Selection}

Having to deal with 623 different features for discriminating songs among 4 classes is probably enough and many features may be redundant or may not bring any useful information to our goal. Indeed, after running many experiments, we tried to keep our models as simple as possible by trying to select the fewer number of features possible.

In the end, we obtained the best results just by using the following features: \textit{Lyric\_vector}, \textit{\%Echoisms}, \textit{\%Duplicate\_Lines}, \textit{isTitleInLyrc}, \textit{\%Past\_tense\_verbs}, \textit{\%Present\_tense\_verbs}, \textit{\%Future\_tense\_verbs}, \textit{\%ADJ}, \textit{\%PUNCT}, \textit{Sentiment} and \textit{Subjectivity\_degree}. This process of feature selection left us with just 310 distinct features per song.












